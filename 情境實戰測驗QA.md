# 情境實戰測驗
## 題目一
> 試想臨時有一活動網頁專案將於近日推出，預期推廣期間訪客流量會是平日常態之百倍（或更多）請簡易描述你/妳將如何確保服務能在推廣期間正常運作？考量的細節是什麼？
> 
由於現職正好有經歷過如雙十一等電商活動，也有幸成為2024年度的雙十一籌備總召，得以對此類高流量活動的應對方式有一個比較系統性的了解。

筆者認為這個問題，可以大致分成幾個步驟跟重點來觀察及說明。

### 流量預估
如果團隊手上還沒有預估流量，可以請比較熟悉相關業務的同仁協助進行預測，或者調用舊有相關資訊來進行比對。

若已經有了預估流量，那麼保險起見，可以先訂定團隊的服務資源標準，至可以支援兩倍或三倍於預估流量的流量，確保服務不會被擊垮，甚或產生雪崩式的服務崩潰。

### 資源準備及壓測
首先應該要確保 Loadbalancer 資源足夠且能正確運作，並且每個機器、服務都要有足夠的冗餘可以提高容錯。

另外不管是使用 VM 或者 k8s 的環境，都須確保 auto scaling 的機制正確運作，並且機器/node/pod 的最大上限也應超過前面所提的需求。

同時也可以雙管齊下，用 jmeter 或 locust 等壓測工具，以前面提及的預估流量為基礎進行壓力測試，得出一個可以正確撐住該大流量的機器數量，並考慮在上線時直接預開機器。如果有成本考量，也可以在觀察一陣子並確認服務穩定之後，手動降低預開機器數量，或完全交由 auto scaling 機制做資源的調整。

### 機器運作狀況及資源監控
同時也應該確保整個 infra 環境的可觀測性，可能利用的工具包括 Grafana/Pormetheus, Opentelemetry/Jeager, ELK stack 等各式工具，並設立明確的告警機制，在服務出現異常或資源不足時，可以立刻通知維運人員進行快速的察看及調整。

### 準備降級方案
如果準備的擴容機制也可能無法應對大量的流量，維運人員也沒辦法馬上而及時的處置，也應該考慮系統降級方案，關閉一些非重要的功能，用少許使用者體驗為代價來換取整體服務的穩定運行。

### 平安度過後的 retro
在平安度過大流量事件之後，也應該整理整個 period 中的相關資料，包括預測流量與具體流量的差異，機器的資源利用率、各種備援方案是否可以如預想中的運作等等。可以做更多緊急應對、系統上及成本方面的優化，也為下一次的類似事件做更好的準備。

## 題目二
> 試想有一個 API 伺服器集群，背後由多台機器組成，此時服務監控系統發現其中一台回應時間經常逾時，僅有此機器異常，請簡易描述你/妳將會如何進行問題排查？考量的細節是什麼？

碰到這類型問題的時候，筆者的處理方式通常會分成幾個步驟。

### 決定應急處理
如果服務重要性較高，並且這台機器的異常可能會影響到公司設立的 SLO/SLA，並且它是可以透過快速重啟解決問題的類型，例如 k8s 中的 pod 或是用 docker compose 起的 docker 等等，可能會先立即將其重啟，事後再慢慢調查。

或者服務是用 VM 的方式提供，為了維護使用者的體驗，應該將異常的機器從 LoadBalancer 上先行下架，並用備份 image 等方式起新服務來供應使用者的需求。
### 展開調查
決定應急處置後，筆者會立即檢查監控系統中的資源使用指標（CPU、內存、磁碟 IO）和服務的健康狀況。結合日誌分析（使用 ELK 堆疊或 CloudWatch），快速定位是否為資源耗盡、服務異常或依賴問題。

### 具體排查
確認完機器本體運作、連線狀況之後，筆者會進一步使用分佈式追蹤工具（如 OpenTelemetry）分析該 API request 路徑，並檢查是否有網絡延遲、下游服務故障等問題。針對硬體問題，筆者會檢查磁碟空間、網絡丟包和運行的 process，確保機器本身運行正常。

### 後續優化與檢討

問題解決後，也應該進行相關問題的分析，例如發現是 memory leak 或 health-check 閾值過低等等問題，並提出改進措施，比如優化監控指標或者定期進行混沌測試，避免類似問題再次發生。

## 題目三
> 試想有一項目運行於 AWS EC2 機器之上，已確認該服務仍然正常運行中，但由於不明原因導致無法再次透過 SSH 登入確認狀態（已確認排除並非網路異常，亦非防火牆阻擋所導致）。請簡易描述你/妳將如何排查問題，並且讓服務恢復正常運作？考量的細節是什麼？如果可以，請試著回答造成無法登入的可能的肇因為何？

這在筆者過去的日常運維工作經驗中，確實是相對常見的異常狀況，在碰到這種狀況時，筆者通常會採取以下步驟進行排查：

### 初步排查：

先登錄至 AWS Console，確認機器是否仍在運作？Metrics 中此機器的效能運用情形如何？同時也確認機器的 Disk 容量是否已滿？又或者是說 VM 內的 Docker 占用過多資源，造成機器當機？一般而言最常見的狀況即是 Disk 容量不足引起，或者 Docker 占用資源過多。

同時也會檢視網路相關設定，不過此例中已明確表達排除，因此按下不表。

再者，若 EC2 Instance Connect 功能有開啟，可以直接嘗試連線，看看是否可以正確進入。如果因安全考量並未開啟類似功能或權限，可以磁碟 mount 到其他 EC2 檢查是否存在 SSH 配置錯誤、權限問題或磁碟空間不足。

### 修復措施

若發現是 Docker 資源問題，直接重啟便可解決，但也應考慮是否該將 instance 資源進行調整，以免再次發生類似問題，亦或者直接採用 k8s 或 ecs 等解決方案。

若是 SSH 相關權限問題，應確保 .ssh/authorized_keys 中包含正確的公鑰，並檢查、修復 /etc/ssh/sshd_config 文件，重新啟動 SSH 服務。也應調整相關文件的權限，避免遭到意外刪改，或者直接採用 ansible 等 IaC 工具，搭配自動化及版控措施，維護 infra 及相關 config 狀態。

再者，若是磁碟已滿問題，就可以將 EBS 內中的不重要內容進行刪除後重新掛載回原機器，同時也應該考慮 log retenion 或其他自動的定期清理機制，以防將來發生相同問題。

## 題目四
> 試想已有一組 ELK/EFK 日誌服務集群，而今日有一新服務上線並且串接日誌紀錄，讓開發者能夠透過 Kibana 進行線上錯誤排查，你/妳會如何將日誌檔內容串接至 ELK/EFK 系統？考量的細節是什麼？

首先必須澄清，比較可惜的是筆者本身在過去工作經驗中，並沒有實際使用 ELK/EFK stack 的經驗，因此以下的內容僅能以查找到的資料作為主要參考依據，並且以下內容會以使用 ELK 為前提來撰寫。

### 配置日誌收集器

如果使用 Filebeat，應在新服務主機上新增 Filebeat 配置，確保日誌能發送至 Logstash，內容可能會類似以下範例。
```
filebeat.inputs:
  - type: log
    paths:
      - /path/to/new-service/logs/*.log
    multiline.pattern: '^\['
    multiline.negate: true
    multiline.match: after

output.logstash:
  hosts: ["logstash-server:5044"]

```

### 結構化與可視化

在 Logstash 中對日誌進行結構化處理，並添加標籤以區分新服務日誌。並在 Kibana 中新增索引模式，創建專屬於新服務的 Dashboard，便於查詢與分析。

### 問題排查

如果日誌無法正確發送到 ELK，應會檢查日誌收集器的輸出日誌，並使用 CURL 或直接查詢 Elasticsearch 索引狀態。又或者若日誌格式有問題，應在 Logstash/Fluentd 中調整解析規則，並在本地進行測試。

以上是本次實戰情境測試的所有回答，感謝您的耐心閱覽。